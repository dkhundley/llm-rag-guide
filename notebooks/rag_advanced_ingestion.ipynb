{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["# RAG Advanced Ingestion\n","In this notebook, we will cover how to apply advanced techniques to your retrieval augmented generation (RAG) ingestion pipeline!"]},{"cell_type":"markdown","metadata":{},"source":["# Notebook Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-23T20:57:18.918905Z","iopub.status.busy":"2024-08-23T20:57:18.918515Z","iopub.status.idle":"2024-08-23T20:57:18.924010Z","shell.execute_reply":"2024-08-23T20:57:18.922901Z","shell.execute_reply.started":"2024-08-23T20:57:18.918874Z"},"trusted":true},"outputs":[],"source":["# Performing the necessary pip installs\n","import os\n","if 'KAGGLE_URL_BASE' in os.environ:\n","    from pip_install import perform_pip_install\n","    # perform_pip_install()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T21:40:25.170270Z","iopub.status.busy":"2024-08-30T21:40:25.169334Z","iopub.status.idle":"2024-08-30T21:40:25.176612Z","shell.execute_reply":"2024-08-30T21:40:25.175331Z","shell.execute_reply.started":"2024-08-30T21:40:25.170209Z"},"trusted":true},"outputs":[],"source":["# Importing the necessary Python libraries\n","import json\n","import yaml\n","\n","import pandas as pd\n","from datasets import Dataset\n","from langchain.vectorstores import FAISS\n","from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_community.document_loaders import DataFrameLoader\n","from langchain_community.docstore.in_memory import InMemoryDocstore\n","from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from ragas import evaluate\n","from ragas.metrics import (\n","    faithfulness,\n","    answer_relevancy,\n","    answer_correctness,\n","    context_recall,\n","    context_precision\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T21:40:39.864602Z","iopub.status.busy":"2024-08-30T21:40:39.864176Z","iopub.status.idle":"2024-08-30T21:40:40.506425Z","shell.execute_reply":"2024-08-30T21:40:40.505429Z","shell.execute_reply.started":"2024-08-30T21:40:39.864570Z"},"trusted":true},"outputs":[],"source":["# Loading the API keys from Kaggle Secrets\n","if 'KAGGLE_URL_BASE' in os.environ:\n","    from load_api_keys import load_api_keys\n","    api_keys = load_api_keys()\n","    \n","# Loading the API keys from local file\n","else:\n","    with open('../keys/api_keys.yaml', 'r') as file:\n","        api_keys = yaml.safe_load(file)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T21:41:30.326554Z","iopub.status.busy":"2024-08-30T21:41:30.326085Z","iopub.status.idle":"2024-08-30T21:41:30.371463Z","shell.execute_reply":"2024-08-30T21:41:30.370324Z","shell.execute_reply.started":"2024-08-30T21:41:30.326518Z"},"trusted":true},"outputs":[],"source":["# Loading in the sample datasets from file\n","if 'KAGGLE_URL_BASE' in os.environ:\n","    df_kis = pd.read_csv('/kaggle/input/synthetic-it-related-knowledge-items/synthetic_knowledge_items.csv')\n","    df_validation = pd.read_csv('/kaggle/input/sample-rag-knowledge-item-dataset/rag_sample_qas_from_kis.csv')\n","else:\n","    df_kis = pd.read_csv('../data/synthetic_knowledge_items.csv')\n","    df_validation = pd.read_csv('../data/rag_sample_qas_from_kis.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ki_topic</th>\n","      <th>ki_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Setting Up a Mobile Device for Company Email</td>\n","      <td>**Setting Up a Mobile Device for Company Email...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Resetting a Forgotten PIN</td>\n","      <td>**Resetting a Forgotten PIN**\\n\\nIf you have f...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Configuring VPN Access for Remote Workers</td>\n","      <td>**Configuring VPN Access for Remote Workers**\\...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Troubleshooting Issues with Microsoft Office</td>\n","      <td>**Troubleshooting Issues with Microsoft Office...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Setting Up a Conference Call on Cisco Webex</td>\n","      <td>To set up a conference call on Cisco Webex, fo...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       ki_topic  \\\n","0  Setting Up a Mobile Device for Company Email   \n","1                     Resetting a Forgotten PIN   \n","2     Configuring VPN Access for Remote Workers   \n","3  Troubleshooting Issues with Microsoft Office   \n","4   Setting Up a Conference Call on Cisco Webex   \n","\n","                                             ki_text  \n","0  **Setting Up a Mobile Device for Company Email...  \n","1  **Resetting a Forgotten PIN**\\n\\nIf you have f...  \n","2  **Configuring VPN Access for Remote Workers**\\...  \n","3  **Troubleshooting Issues with Microsoft Office...  \n","4  To set up a conference call on Cisco Webex, fo...  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Dropping alt_ki_text from the df_kis DataFrame\n","df_kis.drop(columns = ['alt_ki_text'], inplace = True)\n","\n","# Viewing the first few rows of the knowledge item dataframe\n","df_kis.head()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>ground_truth</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>\"How do I set up my company email on my mobile...</td>\n","      <td>To set up your company email on your mobile de...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I forgot my PIN, how can I reset it?</td>\n","      <td>Don't worry, I'm here to help To reset your fo...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>How do I set up VPN access on my laptop so I c...</td>\n","      <td>To set up VPN access on your laptop and access...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\"My Microsoft Word keeps freezing every time I...</td>\n","      <td>I'd be happy to help you troubleshoot the issu...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>How do I set up a conference call on Cisco Web...</td>\n","      <td>To set up a conference call on Cisco Webex wit...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            question  \\\n","0  \"How do I set up my company email on my mobile...   \n","1               I forgot my PIN, how can I reset it?   \n","2  How do I set up VPN access on my laptop so I c...   \n","3  \"My Microsoft Word keeps freezing every time I...   \n","4  How do I set up a conference call on Cisco Web...   \n","\n","                                        ground_truth  \n","0  To set up your company email on your mobile de...  \n","1  Don't worry, I'm here to help To reset your fo...  \n","2  To set up VPN access on your laptop and access...  \n","3  I'd be happy to help you troubleshoot the issu...  \n","4  To set up a conference call on Cisco Webex wit...  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Dropping any unnecessary columns from the validation DataFrame\n","df_validation.drop(columns = ['ki_topic', 'ki_text'], inplace = True)\n","\n","# Renaming the remaining columns\n","df_validation.rename(columns = {\n","    'sample_question': 'question',\n","    'sample_ground_truth': 'ground_truth'\n","}, inplace = True)\n","\n","# Viewing the first few rows of the validation dataframe\n","df_validation.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Chunking Strategies"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Creating the ground truth simulation prompt template\n","ANSWER_GENERATION_PROMPT = '''You are an expert evaluator for question-answering systems. Your task is to provide the ideal answer based on the given question and context. Please follow these guidelines:\n","\n","1. Question: {question}\n","\n","2. Context: {context}\n","\n","3. Instructions:\n","   - Carefully analyze the question and the provided context.\n","   - Formulate a comprehensive and accurate answer based solely on the information given in the context.\n","   - Ensure your answer directly addresses the question.\n","   - Include all relevant information from the context, but do not add any external knowledge.\n","   - If the context doesn't contain enough information to fully answer the question, state this clearly and provide the best possible partial answer.\n","   - Use a formal, objective tone.\n","\n","Remember, your goal is to provide the ideal answer that should be used as the benchmark for evaluating the AI's performance.'''"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-08-23T21:06:28.349885Z","iopub.status.busy":"2024-08-23T21:06:28.349518Z","iopub.status.idle":"2024-08-23T21:06:28.382093Z","shell.execute_reply":"2024-08-23T21:06:28.380907Z","shell.execute_reply.started":"2024-08-23T21:06:28.349857Z"},"trusted":true},"outputs":[],"source":["# Setting the OpenAI API key as an environment variable\n","os.environ['OPENAI_API_KEY'] = api_keys['OPENAI_API_KEY']\n","\n","# Setting up the embedding algorithm\n","embedding_algorithm = OpenAIEmbeddings()\n","\n","# Setting up the chat model\n","chat_model = ChatOpenAI(model = 'chatgpt-4o-latest')\n","\n","# Creating the prompt engineering emplate to generate the simulated ground truth\n","answer_generation_prompt = ChatPromptTemplate.from_messages(messages = [\n","    HumanMessagePromptTemplate.from_template(template = ANSWER_GENERATION_PROMPT)\n","])\n","\n","# Creating the inference chain to generate the simulated answer\n","answer_generation_chain = answer_generation_prompt | chat_model"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def pandas_to_ragas(df):\n","    '''\n","    Converts a Pandas DataFrame into a Ragas-compatible dataset\n","    \n","    Inputs:\n","        - df (Pandas DataFrame): The input DataFrame to be converted\n","        \n","    Returns:\n","        - ragas_testset (Hugging Face Dataset): A Hugging Face dataset compatible with the Ragas framework\n","    '''\n","    # Ensure all text columns are strings and handle NaN values\n","    text_columns = ['question', 'ground_truth', 'answer']\n","    for col in text_columns:\n","        df[col] = df[col].fillna('').astype(str)\n","        \n","    # Convert 'contexts' to a list of lists\n","    df['contexts'] = df['contexts'].fillna('').astype(str).apply(lambda x: [x] if x else [])\n","    \n","    # Converting the DataFrame to a dictionary\n","    data_dict = df[['question', 'contexts', 'answer', 'ground_truth']].to_dict('list')\n","    \n","    # Loading the dictionary as a Hugging Face dataset\n","    ragas_testset = Dataset.from_dict(data_dict)\n","    \n","    return ragas_testset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Defining different chunk sizes to experiment with\n","chunk_sizes = [100, 200, 500, 1000]\n","\n","# Initializing dictionary to store FAISS indexes and DataFrame for evaluation results\n","faiss_indexes = {}\n","df_chunking_results = pd.DataFrame(columns = ['chunk_size', 'answer_correctness', 'answer_relevancy', 'faithfulness', 'context_recall', 'context_precision'])"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating: 100%|██████████| 50/50 [01:18<00:00,  1.56s/it]\n","/var/folders/5q/0hckk7812vs4m11jprtzff600000gn/T/ipykernel_4695/1981613192.py:70: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n","  df_chunking_results = pd.concat([df_chunking_results, new_row], ignore_index = True)\n","Evaluating: 100%|██████████| 50/50 [01:12<00:00,  1.44s/it]\n","Evaluating: 100%|██████████| 50/50 [00:57<00:00,  1.16s/it]\n","Evaluating: 100%|██████████| 50/50 [01:16<00:00,  1.54s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Created FAISS indexes for chunk sizes: [100, 200, 500, 1000]\n","Evaluation results:\n","  chunk_size  answer_correctness  answer_relevancy  faithfulness  \\\n","0        100            0.460825          0.675054      0.378456   \n","1        200            0.396596          0.671702      0.590422   \n","2        500            0.457008          0.774391      0.553076   \n","3       1000            0.617736          0.967614      0.698524   \n","\n","   context_recall  context_precision  \n","0        0.314758                0.4  \n","1        0.335341                0.2  \n","2        0.278637                0.7  \n","3        0.413057                1.0  \n"]}],"source":["# Iterating through each chunk size\n","for chunk_size in chunk_sizes:\n","\n","    # Checking if the chunk size has already been evaluated\n","    if chunk_size not in df_chunking_results['chunk_size'].values:\n","\n","        # Creating a text splitter with the current chunk size\n","        text_splitter = RecursiveCharacterTextSplitter(\n","            chunk_size = chunk_size,\n","            chunk_overlap = 20,\n","            length_function = len\n","        )\n","        \n","        # Loading and splitting the documents\n","        documents = DataFrameLoader(df_kis, page_content_column = 'ki_text').load()\n","        chunks = text_splitter.split_documents(documents)\n","        \n","        # Creating FAISS index for the current chunk size\n","        faiss_index = FAISS.from_documents(chunks, embedding_algorithm)\n","        \n","        # Storing the index\n","        faiss_indexes[chunk_size] = faiss_index\n","\n","        # Creating a retriever from the FAISS index\n","        retriever = faiss_index.as_retriever(search_kwargs = {'k': 1})\n","        \n","        # Generating answers using the retriever and answer generation chain\n","        df_validation['contexts'] = df_validation['question'].apply(lambda q: retriever.invoke(q)[0].page_content)\n","        df_validation['answer'] = df_validation.apply(\n","            lambda row: answer_generation_chain.invoke({\n","                'question': row['question'],\n","                'context': row['contexts']\n","            }).content,\n","            axis = 1\n","        )\n","        \n","        # Converting the DataFrame to a Ragas-compatible dataset\n","        ragas_testset = pandas_to_ragas(df_validation)\n","        \n","        # Evaluating the chunking strategy using ragas\n","        result = evaluate(\n","            dataset = ragas_testset,\n","            llm = chat_model,\n","            metrics = [\n","                answer_correctness,\n","                answer_relevancy,\n","                faithfulness,\n","                context_recall,\n","                context_precision\n","            ]\n","        )\n","        \n","        # Storing the evaluation results in the DataFrame\n","        new_row = pd.DataFrame({\n","            'chunk_size': [chunk_size],\n","            'answer_correctness': [result['answer_correctness']],\n","            'answer_relevancy': [result['answer_relevancy']],\n","            'faithfulness': [result['faithfulness']],\n","            'context_recall': [result['context_recall']],\n","            'context_precision': [result['context_precision']]\n","        })\n","\n","        df_chunking_results = pd.concat([df_chunking_results, new_row], ignore_index = True)\n","    else:\n","        print(f\"Chunk size {chunk_size} already evaluated. Skipping...\")\n","\n","print(f\"Created FAISS indexes for chunk sizes: {list(faiss_indexes.keys())}\")\n","print(\"Evaluation results:\")\n","print(df_chunking_results)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["df_chunking_results.head()\n","df_chunking_results.to_csv('../data/chunking_experiment_results.csv', index = False)"]},{"cell_type":"markdown","metadata":{},"source":["# Optimized Indexing for Fast Retrieval\n","Now that we have covered the chunking strategies, let's move into talking about indexing. To be completely transparent, I struggled to emulate this because pretty much all vector databases come with some sort of indexing algorithm built in! Most commonly, you will run into a particular algorithm called **Hierarchical Navigable Small World (HNSW)**. While there are indeed other options for indexing, we won't necessarily cover those. Again, this is because whether you choose to use Pinecone, Weaviate, AWS OpenSearch, Chroma, FAISS, or one of the other multitude of options out there, you're going to get this indexing optimization built in.\n","\n","Instead, what we'll focus on is comparing retrieval speeds between an index with no special optimizations applied compared to the FAISS in-memory database option that we used in the previous chunking section."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5104322,"sourceId":8796442,"sourceType":"datasetVersion"},{"datasetId":5561282,"sourceId":9198587,"sourceType":"datasetVersion"},{"sourceId":186142459,"sourceType":"kernelVersion"},{"sourceId":188169152,"sourceType":"kernelVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
