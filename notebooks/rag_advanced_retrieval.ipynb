{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Advanced Retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import Dataset\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the data from the CSV files\n",
    "df_kis = pd.read_csv('../data/synthetic_knowledge_items.csv')\n",
    "df_validation = pd.read_csv('../data/rag_sample_qas_from_kis.csv')\n",
    "\n",
    "# Dropping alt_ki_text from the df_kis DataFrame\n",
    "df_kis.drop(columns = ['alt_ki_text'], inplace = True)\n",
    "\n",
    "# Dropping any unnecessary columns from the validation DataFrame\n",
    "df_validation.drop(columns = ['ki_topic', 'ki_text'], inplace = True)\n",
    "\n",
    "# Renaming the remaining columns\n",
    "df_validation.rename(columns = {\n",
    "    'sample_question': 'question',\n",
    "    'sample_ground_truth': 'ground_truth'\n",
    "}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the filepath for the index file\n",
    "index_file = '../data/semantic_index.bin'\n",
    "\n",
    "# Checking if the index file exists\n",
    "if os.path.exists(index_file):\n",
    "\n",
    "    # Load the index from file\n",
    "    faiss_index = FAISS.load_local(index_file,\n",
    "                                   embeddings = OpenAIEmbeddings(),\n",
    "                                   allow_dangerous_deserialization = True)\n",
    "\n",
    "# Creating the FAISS index from scratch\n",
    "else:\n",
    "\n",
    "    # Setting the embedding algorithm\n",
    "    embedding_algorithm = OpenAIEmbeddings()\n",
    "\n",
    "    # Loading the documents\n",
    "    documents = DataFrameLoader(df_kis, page_content_column = 'ki_text').load()\n",
    "\n",
    "    # Creating a semantic text splitter\n",
    "    text_splitter = SemanticChunker(embeddings = embedding_algorithm)\n",
    "\n",
    "    # Splitting the documents into chunks\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Creating FAISS index for the current chunk size\n",
    "    faiss_index = FAISS.from_documents(chunks, embedding_algorithm)\n",
    "\n",
    "    # Save the index to file\n",
    "    faiss_index.save_local(index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file size of ../data/semantic_index.bin is 4.0 kilobytes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_size_kb = os.path.getsize(index_file) / 1024\n",
    "print(f\"The file size of {index_file} is {file_size_kb} kilobytes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
