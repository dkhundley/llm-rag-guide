{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Advanced Retrieval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/vscode/.local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in _VertexAIBase has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in _VertexAICommon has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.11/site-packages/ragas/metrics/__init__.py:4: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from ragas.metrics._answer_correctness import AnswerCorrectness, answer_correctness\n",
      "/home/vscode/.local/lib/python3.11/site-packages/ragas/metrics/__init__.py:7: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from ragas.metrics._context_entities_recall import (\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import Dataset\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_community.document_loaders import DataFrameLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the data from the CSV files\n",
    "df_kis = pd.read_csv('../data/synthetic_knowledge_items.csv')\n",
    "df_validation = pd.read_csv('../data/rag_sample_qas_from_kis.csv')\n",
    "\n",
    "# Dropping alt_ki_text from the df_kis DataFrame\n",
    "df_kis.drop(columns = ['alt_ki_text'], inplace = True)\n",
    "\n",
    "# Dropping any unnecessary columns from the validation DataFrame\n",
    "df_validation.drop(columns = ['ki_topic', 'ki_text'], inplace = True)\n",
    "\n",
    "# Renaming the remaining columns\n",
    "df_validation.rename(columns = {\n",
    "    'sample_question': 'question',\n",
    "    'sample_ground_truth': 'ground_truth'\n",
    "}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the embedding algorithm\n",
    "embedding_algorithm = OpenAIEmbeddings(model = 'text-embedding-3-large')\n",
    "\n",
    "# Setting the chat model\n",
    "chat_model = ChatOpenAI(model = 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the ground truth simulation prompt template\n",
    "ANSWER_GENERATION_PROMPT = '''You are an expert evaluator for question-answering systems. Your task is to provide the ideal answer based on the given question and context. Please follow these guidelines:\n",
    "\n",
    "1. Question: {question}\n",
    "\n",
    "2. Context: {context}\n",
    "\n",
    "3. Instructions:\n",
    "   - Carefully analyze the question and the provided context.\n",
    "   - Formulate a comprehensive and accurate answer based solely on the information given in the context.\n",
    "   - Ensure your answer directly addresses the question.\n",
    "   - Include all relevant information from the context, but do not add any external knowledge.\n",
    "   - If the context doesn't contain enough information to fully answer the question, state this clearly and provide the best possible partial answer.\n",
    "   - Use a formal, objective tone.\n",
    "\n",
    "Remember, your goal is to provide the ideal answer that should be used as the benchmark for evaluating the AI's performance.'''\n",
    "\n",
    "# Creating the prompt engineering emplate to generate the simulated ground truth\n",
    "answer_generation_prompt = ChatPromptTemplate.from_messages(messages = [\n",
    "    HumanMessagePromptTemplate.from_template(template = ANSWER_GENERATION_PROMPT)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Database Setup\n",
    "Since we already covered advanced ingestion techniques in a different notebook, we'll quickly set ourselves up here with a vector database that we can use for practicing our advanced retrieval techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the filepath for the index file\n",
    "index_file = '../data/semantic_index.bin'\n",
    "\n",
    "# Checking if the index file exists\n",
    "if os.path.exists(index_file):\n",
    "\n",
    "    # Load the index from file\n",
    "    faiss_index = FAISS.load_local(index_file,\n",
    "                                   embeddings = embedding_algorithm,\n",
    "                                   allow_dangerous_deserialization = True)\n",
    "\n",
    "# Creating the FAISS index from scratch\n",
    "else:\n",
    "\n",
    "    # Loading the documents\n",
    "    documents = DataFrameLoader(df_kis, page_content_column = 'ki_text').load()\n",
    "\n",
    "    # Creating a semantic text splitter\n",
    "    text_splitter = SemanticChunker(embeddings = embedding_algorithm)\n",
    "\n",
    "    # Splitting the documents into chunks\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Creating FAISS index for the current chunk size\n",
    "    faiss_index = FAISS.from_documents(chunks, embedding_algorithm)\n",
    "\n",
    "    # Save the index to file\n",
    "    faiss_index.save_local(index_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the FAISS index: 269\n"
     ]
    }
   ],
   "source": [
    "# Getting the number of documents in the FAISS index\n",
    "num_documents = faiss_index.index.ntotal\n",
    "\n",
    "# Printing the number of documents\n",
    "print(f'Number of documents in the FAISS index: {num_documents}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Retrieval Techniques\n",
    "Let's move into talking about the advanced retrieval techniques we'll use! For your own use case, you may want to use a different combination of these various techniques. Keep in mind: some of these techniques WILL add latency your pipeline. In addition to applying these techniques to get better results, you will want to ensure that you are balancing the trade-offs between speed and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyDE (Hypothetical Document Embeddings)\n",
    "Don't let the name fool you: this is actually a relatively simple technique. The idea is to take a query and generate a hypothetical document embedding for it. This hypothetical document embedding is then used to retrieve documents from the vector database. This is a great technique to use when you have a query that is very different from the documents in your vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a prompt to help us produce the HyDE generation\n",
    "HyDE_PROMPT = '''Generate a brief, factual paragraph that answers the following question: {question}'''\n",
    "\n",
    "# Setting up the model to use for HyDE generation\n",
    "hyde_model = ChatOpenAI(model = 'gpt-4o-mini')\n",
    "\n",
    "# Creating the prompt engineering template to generate the HyDE information\n",
    "hyde_prompt_template = ChatPromptTemplate.from_messages(messages = [\n",
    "    HumanMessagePromptTemplate.from_template(template = HyDE_PROMPT)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_doc_w_hyde(inputs):\n",
    "    '''\n",
    "    Retrieves a document from the FAISS index using the HyDE generation method\n",
    "\n",
    "    Inputs:\n",
    "    - inputs (dict): A dictionary containing LangChain stuff\n",
    "\n",
    "    Returns:\n",
    "    - context (str): The retrieved document based on the HyDE generation\n",
    "    '''\n",
    "\n",
    "    # Setting the question and HyDe document appropriately\n",
    "    question = inputs['question']\n",
    "    hyde_doc = inputs['hyde_doc']\n",
    "\n",
    "    # Combining the question and HyDE document\n",
    "    combined_query = f'{question}\\n\\n{hyde_doc}'\n",
    "\n",
    "    # Creating a retriever from the FAISS index\n",
    "    retriever = faiss_index.as_retriever(search_kwargs = {'k': 1})\n",
    "\n",
    "    # Retrieving the document from the FAISS index\n",
    "    context = retriever.invoke(combined_query)[0].page_content\n",
    "\n",
    "    return {\n",
    "        'question': question,\n",
    "        'context': context\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the HyDE chain\n",
    "hyde_chain = (\n",
    "    {\n",
    "        'question': RunnablePassthrough(),\n",
    "        'hyde_doc': hyde_prompt_template | hyde_model | StrOutputParser(),\n",
    "    }\n",
    "    | RunnableLambda(retrieve_doc_w_hyde)\n",
    "    | answer_generation_prompt\n",
    "    | chat_model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = df_validation.iloc[0]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"How do I set up my company email on my mobile device?\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To set up your company email on your mobile device, please follow these steps:\\n\\n1. Open the email application on your mobile device. This may be labeled \"Mail\" or \"Email,\" depending on your device\\'s operating system.\\n2. Tap \"Add Account\" or \"Create a new account.\"\\n3. Select \"Exchange\" or \"Corporate\" as the account type.\\n4. Enter your company email address and password.\\n5. If prompted, enter the company\\'s email server address (e.g., mail.company.com).\\n6. Select the desired synchronization options, such as syncing email, contacts, and calendar.\\n\\nNext, configure the email settings as follows:\\n\\n1. In the email account settings, select the \"Advanced\" or \"Security\" option.\\n2. Ensure that the \"Use SSL/TLS\" or \"Use secure connection\" option is enabled.\\n3. Set the authentication method to \"Username and Password\" or \"Domain\\\\Username.\"\\n4. If prompted, enter your company\\'s email domain (e.g., company.com).\\n\\nFinally, verify your email account:\\n\\n1. Wait for the email account to synchronize with the company email server.\\n2. Send a test email to yourself or a colleague to verify that email is sending and receiving correctly.\\n\\nIf you encounter any issues during the setup process, make sure your device has a stable internet connection and that your email credentials are correct. If you are unable to connect to the company email server, contact your IT department for assistance. For email synchronization issues, try restarting your device or checking the email account settings.\\n\\nFor additional security, it is recommended to set up a password or PIN lock on your mobile device. Your company email policies may require further security measures, such as encryption or two-factor authentication; contact your IT department for more information. If you need further assistance or have questions about company email policies, contact your IT department or refer to the company\\'s email policy documentation.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyde_chain.invoke({'question': query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
